{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "from IPython.display import Audio\n",
    "from transformers import AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:11:21 | INFO | speechgpt_logger | Model loaded from openai/whisper-large-v3-turbo\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from model import HuggingFaceWhisperModel\n",
    "\n",
    "args = OmegaConf.create()\n",
    "args.asr_config = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = HuggingFaceWhisperModel.build_model(args, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0c29e63f284a5c855796c499aca945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Oleg\\.cache\\huggingface\\hub\\datasets--distil-whisper--librispeech_long. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024baa1278314781ad929f9ee72c81ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-913508124a40cb97.parquet:   0%|          | 0.00/1.98M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f529d975d5a4bed88a66b4512589386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загружаем тестовый датасет\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "sampling_rate = sample['sampling_rate']\n",
    "\n",
    "waveform = torch.tensor(sample['array']).unsqueeze(0)  # Add batch dimension\n",
    "waveform = waveform.float()\n",
    "\n",
    "inputs = model.processor(waveform.squeeze(0), sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "waveform = inputs['input_features']\n",
    "\n",
    "sf.write('audio.wav',sample['array'], sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "2024-12-30 16:12:25 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "          5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "          2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "            13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "           264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "           949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "          3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "         12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "           534, 10281,   934,   439,    11]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгенерировать токены\n",
    "\n",
    "model.generate(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:13:13 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгенерировать текст\n",
    "\n",
    "model.generate(waveform, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:13:53 | DEBUG | speechgpt_logger | Forward pass complete, logits generated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "            264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "           5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "           2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "             13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "            264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "            949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "           3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "          12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "            534, 10281,   934,   439,    11]]),\n",
       " None,\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# форвард пасс\n",
    "\n",
    "in_features = model.processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "prompt_ids = torch.tensor(model.processor.tokenizer.prefix_tokens).unsqueeze(0)\n",
    "model(src_tokens=in_features, tgt_tokens=prompt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:13:54 | INFO | speechgpt_logger | Parsed waveform from file audio.wav\n",
      "2024-12-30 16:14:34 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгенерировать из текст аудиофайла\n",
    "\n",
    "model.generate(file='audio.wav', text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:14:34 | INFO | speechgpt_logger | Parsed waveform from file audio.wav\n",
      "2024-12-30 16:15:15 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "          5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "          2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "            13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "           264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "           949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "          3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "         12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "           534, 10281,   934,   439,    11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгенерировать токены из аудиофайла\n",
    "\n",
    "model.generate(file='audio.wav')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
