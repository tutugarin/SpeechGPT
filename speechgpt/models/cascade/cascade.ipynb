{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:40:29 | INFO | speechgpt_logger | Building ASR-LLM Cascade Model\n",
      "2024-12-30 16:40:29 | INFO | speechgpt_logger | Loading models: ASR and LLM\n",
      "2024-12-30 16:40:36 | INFO | speechgpt_logger | Model loaded from openai/whisper-large-v3-turbo\n",
      "2024-12-30 16:40:36 | INFO | speechgpt_logger | ASR model loaded successfully\n",
      "2024-12-30 16:40:36 | INFO | speechgpt_logger | Building HuggingFaceQwen2ForCausalLM model.\n",
      "2024-12-30 16:40:36 | INFO | speechgpt_logger | Loading model from Qwen/Qwen2-0.5B\n",
      "2024-12-30 16:40:36 | INFO | speechgpt_logger | Initializing Qwen2Decoder with 24 layers.\n",
      "2024-12-30 16:40:39 | INFO | speechgpt_logger | Qwen2Decoder initialized successfully.\n",
      "2024-12-30 16:40:41 | INFO | speechgpt_logger | Model initialized successfully.\n",
      "2024-12-30 16:40:41 | INFO | speechgpt_logger | Loading model weights.\n",
      "2024-12-30 16:40:44 | INFO | speechgpt_logger | Loaded model weights.\n",
      "2024-12-30 16:40:45 | INFO | speechgpt_logger | LLM model loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AsrLlmCascadeModel(\n",
       "  (asr): HuggingFaceWhisperModel(\n",
       "    (encoder): DummyEncoder()\n",
       "    (decoder): DummyDecoder()\n",
       "    (model): WhisperForConditionalGeneration(\n",
       "      (model): WhisperModel(\n",
       "        (encoder): WhisperEncoder(\n",
       "          (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (embed_positions): Embedding(1500, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x WhisperEncoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): WhisperDecoder(\n",
       "          (embed_tokens): Embedding(51866, 1280, padding_idx=50257)\n",
       "          (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x WhisperDecoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (llm): HuggingFaceQwen2ForCausalLM(\n",
       "    (decoder): Qwen2Decoder(\n",
       "      (embed_tokens): Embedding(151936, 896)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2Attention(\n",
       "            (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "            (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "            (rotary_emb): Qwen2RotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2RotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from model import AsrLlmCascadeModel\n",
    "\n",
    "args = OmegaConf.create()\n",
    "args.llm_config = \"Qwen/Qwen2-0.5B\"\n",
    "args.asr_config = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "cascade = AsrLlmCascadeModel.build_model(args)\n",
    "cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cyESGHlEgnM"
   },
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WnvxIl1Gw4s6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:40:46 | INFO | datasets | PyTorch version 2.5.1 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "waveform = torch.tensor(sample['array']).unsqueeze(0)  # Add batch dimension\n",
    "sampling_rate = sample['sampling_rate']\n",
    "\n",
    "waveform = waveform.float()\n",
    "\n",
    "inputs = cascade.asr.processor(waveform.squeeze(0), sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "waveform = inputs['input_features']\n",
    "\n",
    "sf.write('audio.wav', sample['array'], sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOrhG4v5w4wV",
    "outputId": "31f0312c-ca0a-4ab7-c54a-69b1d5b82491"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:40:58 | INFO | speechgpt_logger | Generating text from ASR\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "2024-12-30 16:41:51 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "          5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "          2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "            13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "           264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "           949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "          3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "         12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "           534, 10281,   934,   439,    11]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. сгенерировать токены\n",
    "cascade.generate_from_asr(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXHz1DxnDr-a",
    "outputId": "3cfaebbd-6d99-40b8-9155-e72a3119859e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:41:52 | INFO | speechgpt_logger | Generating text from ASR\n",
      "2024-12-30 16:42:42 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. сгенерировать текст\n",
    "cascade.generate_from_asr(waveform, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nz63pUNKD6k8",
    "outputId": "caab4185-6d0e-432d-8d11-9e2fae2b9056"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:42:42 | INFO | speechgpt_logger | Generating text from ASR\n",
      "2024-12-30 16:42:42 | INFO | speechgpt_logger | Parsed waveform from file audio.wav\n",
      "2024-12-30 16:43:32 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "          5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "          2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "            13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "           264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "           949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "          3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "         12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "           534, 10281,   934,   439,    11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. сгенерировать токены из аудиофайла\n",
    "cascade.generate_from_asr(file='audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szXmyx-zD4vS",
    "outputId": "38bdc83c-4605-4cfb-a18f-2623129db679"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:43:32 | INFO | speechgpt_logger | Generating text from ASR\n",
      "2024-12-30 16:43:32 | INFO | speechgpt_logger | Parsed waveform from file audio.wav\n",
      "2024-12-30 16:44:22 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. сгенерировать из текст аудиофайла\n",
    "\n",
    "cascade.generate_from_asr(file='audio.wav', text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2jGeV7pD1qE",
    "outputId": "5ce6cc6b-ba24-4996-8040-a44d36ecc243"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:44:22 | DEBUG | speechgpt_logger | Running forward pass\n",
      "2024-12-30 16:45:12 | DEBUG | speechgpt_logger | Forward pass complete, logits generated\n",
      "2024-12-30 16:45:12 | DEBUG | speechgpt_logger | ASR output generated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "            264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "           5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "           2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "             13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "            264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "            949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "           3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "          12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "            534, 10281,   934,   439,    11]]),\n",
       " None,\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. форвард пасс\n",
    "in_features = cascade.asr.processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "prompt_ids = torch.tensor(cascade.asr.processor.tokenizer.prefix_tokens).unsqueeze(0)\n",
    "cascade(src_tokens=in_features, tgt_tokens=prompt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:48:15 | INFO | speechgpt_logger | Parsed waveform from file audio.wav\n",
      "2024-12-30 16:48:55 | DEBUG | speechgpt_logger | Generated speech output, length of generated tokens:1\n",
      "2024-12-30 16:48:55 | INFO | speechgpt_logger | Generated asr_texts [\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\"]\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "2024-12-30 16:51:44 | DEBUG | speechgpt_logger | Generated text successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all, or whether the Christian's taste of it is a real one. If the former is true, he is a scholar of genius. But whether it is true that he is a real scholar, we shall have to wait another hundred years to see. On the other hand, a real Greek may have many ways of telling a simile of his own to his audience; and his audience, which is not so much a moral as a religious man, is not so eager to follow him at all. This he might do. For when the Gospel is in the hands of the ignorant he is like a man who is unable to tell a story of a horse but by using the word. No; as soon as we read any Christian work we see nothing better\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6. Ответ LLM по аудио\n",
    "from speechgpt.logger import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "gen_texts = cascade.generate(logger, file='audio.wav', max_new_tokens=150, do_sample=True, top_k=50, top_p=0.95)\n",
    "for _ in gen_texts:\n",
    "    print(_)\n",
    "    print(\"_________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
