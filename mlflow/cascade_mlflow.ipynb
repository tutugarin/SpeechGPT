{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постинг экземпляра модели на mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Инициализация модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 14:27:11 | INFO | speechgpt_logger | Building ASR-LLM Cascade Model\n",
      "2024-12-31 14:27:11 | INFO | speechgpt_logger | Loading models: ASR and LLM\n",
      "2024-12-31 14:27:15 | INFO | speechgpt_logger | Model loaded from openai/whisper-large-v3-turbo\n",
      "2024-12-31 14:27:15 | INFO | speechgpt_logger | ASR model loaded successfully\n",
      "2024-12-31 14:27:15 | INFO | speechgpt_logger | Building HuggingFaceQwen2ForCausalLM model.\n",
      "2024-12-31 14:27:15 | INFO | speechgpt_logger | Loading model from Qwen/Qwen2-0.5B\n",
      "2024-12-31 14:27:15 | INFO | speechgpt_logger | Initializing Qwen2Decoder with 24 layers.\n",
      "2024-12-31 14:27:20 | INFO | speechgpt_logger | Qwen2Decoder initialized successfully.\n",
      "2024-12-31 14:27:22 | INFO | speechgpt_logger | Model initialized successfully.\n",
      "2024-12-31 14:27:22 | INFO | speechgpt_logger | Loading model weights.\n",
      "2024-12-31 14:27:24 | INFO | speechgpt_logger | Loaded model weights.\n",
      "2024-12-31 14:27:24 | INFO | speechgpt_logger | LLM model loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AsrLlmCascadeModel(\n",
       "  (asr): HuggingFaceWhisperModel(\n",
       "    (encoder): DummyEncoder()\n",
       "    (decoder): DummyDecoder()\n",
       "    (model): WhisperForConditionalGeneration(\n",
       "      (model): WhisperModel(\n",
       "        (encoder): WhisperEncoder(\n",
       "          (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (embed_positions): Embedding(1500, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x WhisperEncoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): WhisperDecoder(\n",
       "          (embed_tokens): Embedding(51866, 1280, padding_idx=50257)\n",
       "          (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x WhisperDecoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (llm): HuggingFaceQwen2ForCausalLM(\n",
       "    (decoder): Qwen2Decoder(\n",
       "      (embed_tokens): Embedding(151936, 896)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2Attention(\n",
       "            (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "            (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "            (rotary_emb): Qwen2RotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2RotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from omegaconf import OmegaConf\n",
    "from speechgpt.models import AsrLlmCascadeModel\n",
    "\n",
    "args = OmegaConf.create()\n",
    "args.llm_config = \"Qwen/Qwen2-0.5B\"\n",
    "args.asr_config = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "cascade = AsrLlmCascadeModel.build_model(args)\n",
    "cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "AsrLlmCascadeModel                                                --\n",
       "├─HuggingFaceWhisperModel: 1-1                                    --\n",
       "│    └─DummyEncoder: 2-1                                          --\n",
       "│    └─DummyDecoder: 2-2                                          --\n",
       "│    └─WhisperForConditionalGeneration: 2-3                       --\n",
       "│    │    └─WhisperModel: 3-1                                     808,878,080\n",
       "│    │    └─Linear: 3-2                                           66,388,480\n",
       "├─HuggingFaceQwen2ForCausalLM: 1-2                                --\n",
       "│    └─Qwen2Decoder: 2-4                                          --\n",
       "│    │    └─Embedding: 3-3                                        136,134,656\n",
       "│    │    └─ModuleList: 3-4                                       357,897,216\n",
       "│    │    └─Qwen2RMSNorm: 3-5                                     896\n",
       "│    │    └─Qwen2RotaryEmbedding: 3-6                             --\n",
       "│    └─Linear: 2-5                                                136,134,656\n",
       "==========================================================================================\n",
       "Total params: 1,505,433,984\n",
       "Trainable params: 1,503,513,984\n",
       "Non-trainable params: 1,920,000\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(cascade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Синтетическая кривая потерь**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss(loss):\n",
    "    epochs = np.arange(len(loss)) + 1\n",
    "    best_epoch = np.argmin(loss).flatten()[0] + 1\n",
    "    best_train_loss = loss[best_epoch - 1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.plot(epochs, loss)\n",
    "    ax.axvline(best_epoch, c=\"black\", zorder=1)\n",
    "    ax.scatter(best_epoch, best_train_loss, c=\"lime\", marker=\"x\", zorder=2,\n",
    "               label=f\"Best epoch: {best_epoch}\\nBest loss: {best_train_loss:.4f}\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Train loss\")\n",
    "    ax.set_title(\"Train loss dynamics plot\")\n",
    "\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка на локально запущенный mlflow-сервер**\n",
    "\n",
    "Для этого в `.env` указываем `MLFLOW_TRACKING_URI=\"http://localhost:5000\"`, если запускаем локально. На удаленном сервере -- пока не предусмотрено\n",
    "\n",
    "**Создаем эксперимент**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'568664667297304622'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(\"speechgpt_cascade\").experiment_id\n",
    "except:\n",
    "    exp_id = mlflow.set_experiment(\"speechgpt_cascade\").experiment_id\n",
    "\n",
    "exp_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создаем первый run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run cascade_run_1 at: http://localhost:5000/#/experiments/568664667297304622/runs/123bb073b3ab4141ae1ca44f94f05a83\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/568664667297304622\n"
     ]
    }
   ],
   "source": [
    "run_name=\"cascade_run_1\"\n",
    "run_description = \"\"\"SpeechGPT first cascade iteration\"\"\"\n",
    "\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=run_name, description=run_description):  # run_name можно тоже поменять\n",
    "    epochs = np.arange(1, 101)\n",
    "    loss = 2 / np.sqrt(epochs) + np.random.normal(scale=0.03, size=100)\n",
    "    best_epoch = np.argmin(loss).flatten()[0] + 1\n",
    "    best_train_loss = loss[best_epoch - 1]\n",
    "    \n",
    "    fig1 = plot_loss(loss)\n",
    "    \n",
    "    # mlflow.pytorch.log_model(cascade, \"cascade\")\n",
    "    mlflow.log_param(\"epochs\", len(epochs))\n",
    "    mlflow.log_param(\"learning rate\", 1e-4)\n",
    "    mlflow.log_metrics({\n",
    "        \"Best train loss\": best_train_loss,\n",
    "        \"Best train epoch\": best_epoch,\n",
    "    })\n",
    "\n",
    "    mlflow.log_figure(fig1, \"train_loss.png\")\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(cascade)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создаем второй run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run cascade_run_2 at: http://localhost:5000/#/experiments/568664667297304622/runs/62ce49212b334f9db4f18451b5f7eee8\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/568664667297304622\n"
     ]
    }
   ],
   "source": [
    "run_name=\"cascade_run_2\"\n",
    "run_description = \"\"\"SpeechGPT second cascade iteration\"\"\"\n",
    "\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=run_name, description=run_description):  # run_name можно тоже поменять\n",
    "    epochs = np.arange(1, 101)\n",
    "    loss = 2.5 / np.sqrt(epochs) + np.random.normal(scale=0.05, size=100)\n",
    "    best_epoch = np.argmin(loss).flatten()[0] + 1\n",
    "    best_train_loss = loss[best_epoch - 1]\n",
    "    \n",
    "    fig2 = plot_loss(loss)\n",
    "    \n",
    "    # mlflow.pytorch.log_model(cascade, \"cascade\")\n",
    "    mlflow.log_param(\"epochs\", len(epochs))\n",
    "    mlflow.log_param(\"learning rate\", 1e-5)\n",
    "    mlflow.log_metrics({\n",
    "        \"Best train loss\": best_train_loss,\n",
    "        \"Best train epoch\": best_epoch,\n",
    "    })\n",
    "\n",
    "    mlflow.log_figure(fig2, \"train_loss.png\")\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(cascade)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62ce49212b334f9db4f18451b5f7eee8</td>\n",
       "      <td>cascade_run_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123bb073b3ab4141ae1ca44f94f05a83</td>\n",
       "      <td>cascade_run_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id tags.mlflow.runName\n",
       "0  62ce49212b334f9db4f18451b5f7eee8       cascade_run_2\n",
       "1  123bb073b3ab4141ae1ca44f94f05a83       cascade_run_1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs = mlflow.search_runs(search_all_experiments=True)[[\"run_id\", \"tags.mlflow.runName\"]]\n",
    "all_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'62ce49212b334f9db4f18451b5f7eee8'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = \"cascade_run_2\"\n",
    "run_id = all_runs.loc[all_runs[\"tags.mlflow.runName\"] == run_name][\"run_id\"].values[0]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff98db69a95c4352910cc684f572cdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = mlflow.get_run(run_id)\n",
    "metrics = run.data.metrics\n",
    "params = run.data.params\n",
    "artifacts_path = mlflow.artifacts.download_artifacts(run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_summary.txt', 'train_loss.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(artifacts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best train epoch</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best train loss</td>\n",
       "      <td>0.141414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1\n",
       "0  Best train epoch  91.000000\n",
       "1   Best train loss   0.141414"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(metrics.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Best train epoch': 91.0, 'Best train loss': 0.1414139378686599}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
